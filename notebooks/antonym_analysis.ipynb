{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please use the Local ./Dockerfile environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install the faiss-cpu when new env is provisioned\n",
    "#!pip install faiss-cpu\n",
    "#conda install -c pytorch faiss-cpu=1.7.4 mkl=2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install the openai when new env is provisioned\n",
    "#!pip install openai\n",
    "\n",
    "#conda install -c conda-forge openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import umap\n",
    "import faiss\n",
    "import openai\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import altair as alt\n",
    "import configparser\n",
    "#from sklearn import decomposition\n",
    "\n",
    "\n",
    "#alt.data_transformers.disable_max_rows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional in Jupyter Notebook: requires an up-to-date vega nbextension.\n",
    "#alt.renderers.enable('notebook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.5.3'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.7.4'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make sure we are using FAISS version 1.7.4 \n",
    "faiss.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare required resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>product_title</th>\n",
       "      <th>review_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B00001QHXX</td>\n",
       "      <td>R2HBUQ97RV5JVR</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Richard Nixon Mask</td>\n",
       "      <td>I got this mask for a company party and it fre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B00001QHXX</td>\n",
       "      <td>RHCH92YNAS282</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Richard Nixon Mask</td>\n",
       "      <td>Nice mask, will have to do some fitting work. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B00001QHXX</td>\n",
       "      <td>R1OHYB07D0WE35</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Richard Nixon Mask</td>\n",
       "      <td>Even though its a bit large, I can't help but ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id       review_id  star_rating       product_title  \\\n",
       "0  B00001QHXX  R2HBUQ97RV5JVR          3.0  Richard Nixon Mask   \n",
       "1  B00001QHXX   RHCH92YNAS282          4.0  Richard Nixon Mask   \n",
       "2  B00001QHXX  R1OHYB07D0WE35          5.0  Richard Nixon Mask   \n",
       "\n",
       "                                         review_body  \n",
       "0  I got this mask for a company party and it fre...  \n",
       "1  Nice mask, will have to do some fitting work. ...  \n",
       "2  Even though its a bit large, I can't help but ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This dataframe is created with the amazon_reviews_us_Apparel_v1_00.tsv.gz dataset with following filtering criteria:\n",
    "# 1. Year 2015\n",
    "# 2. Products with 15 - 25 reviews\n",
    "# 3. review_lenght > 10\n",
    "\n",
    "df_apparel = pd.read_csv('../resources/data/apparel_10to14.tsv.gz', sep='\\t', compression='gzip')\n",
    "cols = ['product_id', 'review_id', 'star_rating', 'product_title', 'review_body']\n",
    "df_apparel = df_apparel[cols]\n",
    "df_apparel.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-created FAISS index\n",
    "faiss_index = faiss.read_index('../resources/binary/apparel_10to14_review_cosine.faissindex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your API key from an environment variable or secret management service\n",
    "config = configparser.ConfigParser()\n",
    "config.read('nes.ini')\n",
    "openai.api_key = config['OpenAI']['api_key']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to create the query embedding. Make sure to use the same model as what we used to created the product embedding\n",
    "def get_embedding(text, model=\"text-embedding-ada-002\"):\n",
    "   text = text.replace(\"\\n\", \" \")\n",
    "   \n",
    "   return np.array(openai.Embedding.create(input = [text], model=model)['data'][0]['embedding'], dtype='float32').reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_with_original_query(df, faiss_index, query_embedding, num_of_records=100):\n",
    "    # we need to normalize the question embedding in order to use cosine similarity to search \n",
    "    faiss.normalize_L2(query_embedding)\n",
    "\n",
    "    # distance is the correspnding distance\n",
    "    # result_idx is the index of the input array, hence the index of the dataframe (if the dataframe index is reset which starts with 0)\n",
    "    distance, result_idx = faiss_index.search(query_embedding, k=num_of_records)\n",
    "\n",
    "    # use the return index to create the result dataframe\n",
    "    df_result = df.iloc[result_idx.squeeze().tolist()]\n",
    "    # add Distance to the result dataframe\n",
    "    df_result['distance'] = distance.T\n",
    "\n",
    "    df_result = df_result.sort_values(by='distance', ascending=True)\n",
    "    \n",
    "    return df_result, result_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_rewrite =\"\"\"\n",
    "    You are an English teacher. You need to find every single adjective from the sentences delimited by triple backquotes below.\n",
    "    Then you rewrite the sentences by changing the adjectives in their opposite meaning. \n",
    "    Finally, you only need to output the rewritten sentences.\n",
    "\n",
    "    ```{}```\n",
    "\"\"\"\n",
    "\n",
    "prompt_antonym=\"\"\"\n",
    "    You are an English teacher. You need to find every single ADJECTIVE from the sentences delimited by triple backquotes below.\n",
    "    Then, you transform every adjective into its antonym.\n",
    "    Finally, give the dictionary meaning for each antonym.\n",
    "    Below are two examples. You need to comlete the third one. \n",
    "    \n",
    "\n",
    "    Text 1: Kids flip flops for girl, cute, good fit, comfortable and durable, low price\n",
    "    Output 1: Artless means without guile or deception. Unsuited means not proper or fitting for something. Uncomfortable means causing discomfort.  Fragile means easily broken. Costly means expensive.\n",
    "    ## \n",
    "    Text 2: Long sleeve shirts for men. Wrinkle-free, thick but breathable and slim fit\n",
    "    Output 2: Short means having little length. Crinkle means to form many short bends or ripples. Thin means measuring little in cross section or diameter. Airtight means impermeable to air or nearly so. Wide means having a greater than usual measure across\n",
    "    ##\n",
    "    Text 3:  ```{}```\n",
    "    Output 3:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_opposite_query(orignal_query='', prompt=''):\n",
    "\n",
    "    response = openai.Completion.create(\n",
    "        model=\"text-davinci-003\",\n",
    "        prompt=prompt.format(orignal_query),\n",
    "        temperature=0,\n",
    "        max_tokens=1000,\n",
    "        frequency_penalty=0.0,\n",
    "        presence_penalty=0.0\n",
    "    )\n",
    "\n",
    "    return response['choices'][0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_with_opposite_query(df, faiss_index, opposite_query_embedding, original_query_result_index, num_of_records=100):\n",
    "\n",
    "    faiss.normalize_L2(opposite_query_embedding)\n",
    "\n",
    "    # we want to make sure the opposite query only compare against the texts found by the original query \n",
    "    id_selector = faiss.IDSelectorArray(original_query_result_index.shape[1], faiss.swig_ptr(original_query_result_index))\n",
    "    filtered_distances, filtered_indices = faiss_index.search(opposite_query_embedding, k=num_of_records, params=faiss.SearchParametersIVF(sel=id_selector))\n",
    "\n",
    "    df_opposite_result = df.iloc[filtered_indices.squeeze().tolist()]\n",
    "    df_opposite_result['distance'] = filtered_distances.T\n",
    "\n",
    "    df_opposite_result = df_opposite_result.sort_values(by='distance', ascending=False)\n",
    "\n",
    "    return df_opposite_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reconcile_result(df_result_original, df_result_opposite):\n",
    "\n",
    "    df_reconcile_result = df_result_original.merge(df_result_opposite[['review_id', 'distance']], \n",
    "                            left_on='review_id', right_on='review_id', how='left', suffixes=('_original', '_opposite'))\n",
    "    \n",
    "    # Using Dot Product FAISS Index with L2 normaliztion, the returning result is Cosine Similiarty, rather than Distance.\n",
    "    # There will turn the Cosine Similarity to Distance \n",
    "    df_reconcile_result['distance_original'] = 1 - df_reconcile_result['distance_original']\n",
    "    df_reconcile_result['distance_opposite'] = 1 - df_reconcile_result['distance_opposite']\n",
    "\n",
    "    return df_reconcile_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to clip the distance_opposite\n",
    "\n",
    "def clip_distance_opposite(df, clipping=0.5):\n",
    "    df = df.sort_values(by='distance_opposite', ascending=False).reset_index(drop=True)\n",
    "    # Flatten the first n% with distance_opposite sorted in descending order  \n",
    "    quantile_value = df['distance_opposite'].quantile(q=(1-clipping))\n",
    "    df.loc[0:(clipping * len(df)), ['distance_opposite']] = quantile_value\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to calculate adjsuted distance using the distance_oppsite as a penalty term\n",
    "\n",
    "def cal_adjusted_distance(df, k=0.5):\n",
    "    df['distance_adjusted'] = df.apply(lambda row: row['distance_original'] + (k * 1/row['distance_opposite']), axis='columns')\n",
    "    \n",
    "    return df \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to calculate review level similarity scores\n",
    "\n",
    "def cal_review_similarity_score(df):\n",
    "    # find max of distance_adjusted  \n",
    "    max_distance_adjusted  = df['distance_adjusted'].max()\n",
    "    # normalized adjusted distance then subtract from 1 to calculate the similarity score \n",
    "    df['similarity_score'] = df['distance_adjusted'].apply(lambda x: 1 - x / max_distance_adjusted)\n",
    "\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to calculate the product level similarity scores \n",
    "\n",
    "def cal_product_similarity_score(df, method='discount_reward'):\n",
    "\n",
    "    if method == 'average':\n",
    "        df_temp = df.groupby('product_id')['similarity_score'].mean()\n",
    "        df_temp = df_temp.to_frame(name='product_similarity_score').reset_index()\n",
    "        df = pd.merge(df, df_temp, left_on='product_id', right_on='product_id')\n",
    "    else:\n",
    "        df_grouped = df.groupby(by='product_id')\n",
    "\n",
    "        for name, data in df_grouped:\n",
    "            data = data.sort_values('similarity_score', ascending=False)\n",
    "            scores = []\n",
    "            for cnt, (index, row) in enumerate(data.iterrows()):\n",
    "                discounted_score = row['similarity_score'] / pow(2, cnt)\n",
    "                scores.append(discounted_score)\n",
    "            df.loc[data.index, 'product_similarity_score'] = sum(scores)\n",
    "        \n",
    "    df = df.sort_values(by=['product_similarity_score', 'similarity_score'], ascending=[False, False])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_search_result(df_reconcile_result, clipping=0, weight=0, method='discount_reward'):\n",
    "    \"\"\"\n",
    "    Method 1:   Calculate product level similarity score by Average\n",
    "                clipping=0, weight=0, method='average'\n",
    "\n",
    "    Method 2:   Calculate product level similarity score by Discount Reward\n",
    "                clipping=0, weight=0, method='discount_reward' \n",
    "\n",
    "    Method 3:   Calcuate product level similarity score by Discount Reward with Adjustment by Opposite Query \n",
    "                clipping=0.1, weight=0.5, method='discount_reward\n",
    "    \"\"\"\n",
    "\n",
    "    df_copy = df_reconcile_result.copy()\n",
    "\n",
    "    df_copy = clip_distance_opposite(df_copy, clipping=clipping)\n",
    "    df_copy = cal_adjusted_distance(df_copy, k=weight)\n",
    "    df_copy = cal_review_similarity_score(df_copy)\n",
    "    df_copy = cal_product_similarity_score(df_copy, method=method)\n",
    "\n",
    "    # re-arrange columns for output\n",
    "    cols = ['product_id', 'review_id', 'star_rating', 'distance_original', 'distance_opposite',\n",
    "            'distance_adjusted', 'similarity_score', 'product_similarity_score', 'product_title', 'review_body']\n",
    "\n",
    "    df_copy = df_copy[cols]\n",
    "\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geneate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adj = pd.DataFrame(['Long','Short','Thin','Thick','Breathable','Stuffy','Cool','Hot'], columns=['adjective'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adj['embedding'] = df_adj['adjective'].apply(lambda x: get_embedding(x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adjective</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Long</td>\n",
       "      <td>[0.0048255734, 0.0027919388, 0.016544823, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Short</td>\n",
       "      <td>[-0.01411955, 0.009450202, 0.009687154, -0.007...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thin</td>\n",
       "      <td>[-0.012029518, -0.005202453, 0.0058670673, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Thick</td>\n",
       "      <td>[-0.015147983, -0.008822895, -0.0086416025, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Breathable</td>\n",
       "      <td>[-0.010382047, 0.012713247, -0.0114918295, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Stuffy</td>\n",
       "      <td>[-0.0042448253, -0.010555807, -0.008107787, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Cool</td>\n",
       "      <td>[-0.009752826, -0.005435001, 0.015460701, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hot</td>\n",
       "      <td>[-0.028340444, -0.0046487427, -0.0106000975, -...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    adjective                                          embedding\n",
       "0        Long  [0.0048255734, 0.0027919388, 0.016544823, -0.0...\n",
       "1       Short  [-0.01411955, 0.009450202, 0.009687154, -0.007...\n",
       "2        Thin  [-0.012029518, -0.005202453, 0.0058670673, 0.0...\n",
       "3       Thick  [-0.015147983, -0.008822895, -0.0086416025, -0...\n",
       "4  Breathable  [-0.010382047, 0.012713247, -0.0114918295, -0....\n",
       "5      Stuffy  [-0.0042448253, -0.010555807, -0.008107787, -0...\n",
       "6        Cool  [-0.009752826, -0.005435001, 0.015460701, -0.0...\n",
       "7         Hot  [-0.028340444, -0.0046487427, -0.0106000975, -..."
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_adj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UAMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a func to handle the mixed- type data and return the final UMAP embeddings\n",
    "def umap_embed(df, n_components=2,  n_neighbors= 15, random_state=42):\n",
    "    #reducer = umap.UMAP(random_state=RAMDOM_STATE, n_components=2, metric='cosine', n_neighbors=10)\n",
    "    reducer = umap.UMAP(random_state=random_state, n_components=n_components, n_neighbors=n_neighbors, metric='cosine')\n",
    "    #reducer = umap.UMAP(random_state=random_state, n_components=n_components, n_neighbors=n_neighbors)\n",
    "    reducer.fit(df)\n",
    "    umap_embedding = reducer.transform(df)\n",
    "   \n",
    "    return reducer, umap_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_dataframe_for_vis(umap_embedding):\n",
    "\n",
    "    df = pd.DataFrame(umap_embedding)\n",
    "    df.index.name='Review'\n",
    "    df = df.reset_index()\n",
    "    df.columns = [str(c) for c in df.columns]\n",
    "    df = df.melt(id_vars=['Review'])\n",
    "    df['variable'] = df['variable'].astype('int64')\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adj_vector = pd.DataFrame(df_adj['embedding'].values.tolist()).add_prefix('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "reducer, umap_adj = umap_embed(df_adj_vector, n_components=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12.45661 , 12.676853, 13.441979, 14.08781 , 14.827417, 14.233771,\n",
       "       13.417243, 13.264073], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "umap_adj[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adj['comp1'] = pd.Series(umap_adj[:,0])\n",
    "df_adj['comp2'] = pd.Series(umap_adj[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adjective</th>\n",
       "      <th>embedding</th>\n",
       "      <th>comp1</th>\n",
       "      <th>comp2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Long</td>\n",
       "      <td>[0.0048255734, 0.0027919388, 0.016544823, -0.0...</td>\n",
       "      <td>12.456610</td>\n",
       "      <td>16.359022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Short</td>\n",
       "      <td>[-0.01411955, 0.009450202, 0.009687154, -0.007...</td>\n",
       "      <td>12.676853</td>\n",
       "      <td>15.492501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thin</td>\n",
       "      <td>[-0.012029518, -0.005202453, 0.0058670673, 0.0...</td>\n",
       "      <td>13.441979</td>\n",
       "      <td>15.418947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Thick</td>\n",
       "      <td>[-0.015147983, -0.008822895, -0.0086416025, -0...</td>\n",
       "      <td>14.087810</td>\n",
       "      <td>15.788052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Breathable</td>\n",
       "      <td>[-0.010382047, 0.012713247, -0.0114918295, -0....</td>\n",
       "      <td>14.827417</td>\n",
       "      <td>16.626968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Stuffy</td>\n",
       "      <td>[-0.0042448253, -0.010555807, -0.008107787, -0...</td>\n",
       "      <td>14.233771</td>\n",
       "      <td>17.117733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Cool</td>\n",
       "      <td>[-0.009752826, -0.005435001, 0.015460701, -0.0...</td>\n",
       "      <td>13.417243</td>\n",
       "      <td>17.355389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hot</td>\n",
       "      <td>[-0.028340444, -0.0046487427, -0.0106000975, -...</td>\n",
       "      <td>13.264073</td>\n",
       "      <td>16.614950</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    adjective                                          embedding      comp1  \\\n",
       "0        Long  [0.0048255734, 0.0027919388, 0.016544823, -0.0...  12.456610   \n",
       "1       Short  [-0.01411955, 0.009450202, 0.009687154, -0.007...  12.676853   \n",
       "2        Thin  [-0.012029518, -0.005202453, 0.0058670673, 0.0...  13.441979   \n",
       "3       Thick  [-0.015147983, -0.008822895, -0.0086416025, -0...  14.087810   \n",
       "4  Breathable  [-0.010382047, 0.012713247, -0.0114918295, -0....  14.827417   \n",
       "5      Stuffy  [-0.0042448253, -0.010555807, -0.008107787, -0...  14.233771   \n",
       "6        Cool  [-0.009752826, -0.005435001, 0.015460701, -0.0...  13.417243   \n",
       "7         Hot  [-0.028340444, -0.0046487427, -0.0106000975, -...  13.264073   \n",
       "\n",
       "       comp2  \n",
       "0  16.359022  \n",
       "1  15.492501  \n",
       "2  15.418947  \n",
       "3  15.788052  \n",
       "4  16.626968  \n",
       "5  17.117733  \n",
       "6  17.355389  \n",
       "7  16.614950  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_adj.to_csv('../resources/data/temp/df_adj.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adj = pd.read_csv('../resources/data/temp/df_adj.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = [[0.6, 5.5, 'Breathable'],\n",
    "               [1.2, 5.0, 'Stuffy'],\n",
    "               [1.3, 6.3, 'Thick'],\n",
    "               [1.8, 7.0, 'Thin'],\n",
    "               [2.0, 3.5, 'Cool'],\n",
    "               [2.1, 5.5, 'Hot'],\n",
    "               [2.5, 6.5, 'Short'],\n",
    "               [3.0, 6.0, 'Long']]\n",
    "               \n",
    "df_ann = pd.DataFrame(annotations, columns=['comp1', 'comp2', 'adjective'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-38ef36a0277246689f788ec9f5313cb4.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-38ef36a0277246689f788ec9f5313cb4.vega-embed details,\n",
       "  #altair-viz-38ef36a0277246689f788ec9f5313cb4.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-38ef36a0277246689f788ec9f5313cb4\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-38ef36a0277246689f788ec9f5313cb4\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-38ef36a0277246689f788ec9f5313cb4\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.8.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.8.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"layer\": [{\"data\": {\"name\": \"data-4ab2cd03425d9846628bef8b36716a1a\"}, \"mark\": {\"type\": \"circle\", \"color\": \"orange\", \"size\": 200}, \"encoding\": {\"tooltip\": [{\"field\": \"adjective\", \"type\": \"nominal\"}], \"x\": {\"field\": \"comp1\", \"scale\": {\"domain\": [0, 4]}, \"type\": \"quantitative\"}, \"y\": {\"field\": \"comp2\", \"scale\": {\"domain\": [0, 8]}, \"type\": \"quantitative\"}}, \"name\": \"view_1\"}, {\"data\": {\"name\": \"data-e30d79e626132c57a77f8ecb6ad6e9fd\"}, \"mark\": {\"type\": \"text\", \"fontSize\": 15}, \"encoding\": {\"text\": {\"field\": \"adjective\", \"type\": \"nominal\"}, \"x\": {\"field\": \"comp1\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"comp2\", \"type\": \"quantitative\"}}}], \"height\": 400, \"params\": [{\"name\": \"param_1\", \"select\": {\"type\": \"interval\", \"encodings\": [\"x\", \"y\"]}, \"bind\": \"scales\", \"views\": [\"view_1\"]}], \"width\": 600, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.8.0.json\", \"datasets\": {\"data-4ab2cd03425d9846628bef8b36716a1a\": [{\"adjective\": \"Long\", \"embedding\": \"[ 0.00482557  0.00279194  0.01654482 ... -0.00607678  0.00453604\\n -0.0200606 ]\", \"comp1\": 3.1462076, \"comp2\": 5.3619313}, {\"adjective\": \"Short\", \"embedding\": \"[-0.01411955  0.0094502   0.00968715 ... -0.00701447  0.00479479\\n -0.021479  ]\", \"comp1\": 2.667685, \"comp2\": 6.022793}, {\"adjective\": \"Thin\", \"embedding\": \"[-0.01202952 -0.00520245  0.00586707 ... -0.01521228 -0.01871258\\n -0.0251815 ]\", \"comp1\": 1.9551865, \"comp2\": 6.4003024}, {\"adjective\": \"Thick\", \"embedding\": \"[-0.01514798 -0.00882289 -0.0086416  ... -0.01624917 -0.03115543\\n -0.01469139]\", \"comp1\": 1.3549395, \"comp2\": 5.76024}, {\"adjective\": \"Breathable\", \"embedding\": \"[-0.01036034  0.01275674 -0.01147647 ... -0.00705133 -0.0043759\\n -0.00829878]\", \"comp1\": 0.7292193, \"comp2\": 5.00731}, {\"adjective\": \"Stuffy\", \"embedding\": \"[-0.00424483 -0.01055581 -0.00810779 ...  0.00351519 -0.01150365\\n -0.02393468]\", \"comp1\": 1.2707111, \"comp2\": 4.4686117}, {\"adjective\": \"Cool\", \"embedding\": \"[-0.00975283 -0.005435    0.0154607  ... -0.01165331 -0.02215092\\n -0.02956024]\", \"comp1\": 2.2184901, \"comp2\": 4.3910193}, {\"adjective\": \"Hot\", \"embedding\": \"[-0.02834044 -0.00464874 -0.0106001  ...  0.00238468 -0.02136561\\n -0.03134541]\", \"comp1\": 2.2780898, \"comp2\": 5.138867}], \"data-e30d79e626132c57a77f8ecb6ad6e9fd\": [{\"comp1\": 0.6, \"comp2\": 5.5, \"adjective\": \"Breathable\"}, {\"comp1\": 1.2, \"comp2\": 5.0, \"adjective\": \"Stuffy\"}, {\"comp1\": 1.3, \"comp2\": 6.3, \"adjective\": \"Thick\"}, {\"comp1\": 1.8, \"comp2\": 7.0, \"adjective\": \"Thin\"}, {\"comp1\": 2.0, \"comp2\": 3.5, \"adjective\": \"Cool\"}, {\"comp1\": 2.1, \"comp2\": 5.5, \"adjective\": \"Hot\"}, {\"comp1\": 2.5, \"comp2\": 6.5, \"adjective\": \"Short\"}, {\"comp1\": 3.0, \"comp2\": 6.0, \"adjective\": \"Long\"}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scatter_plot = alt.Chart(data=df_adj).mark_circle(size=200, color='orange').encode(\n",
    "        x=alt.X('comp1:Q').scale(domain=(0,4)),\n",
    "        y=alt.Y('comp2:Q').scale(domain=(0,8)),\n",
    "        tooltip=[\n",
    "            'adjective:N'\n",
    "            ]\n",
    ")\n",
    "\n",
    "ann_plot = alt.Chart(data=df_ann).mark_text(fontSize=15).encode(\n",
    "    x=alt.X('comp1:Q'),\n",
    "    y=alt.Y('comp2:Q'),\n",
    "    text=alt.Text('adjective:N')\n",
    ")\n",
    "\n",
    "(scatter_plot + ann_plot).properties(\n",
    "    width=600,\n",
    "    height=400\n",
    ").interactive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "47c21ec07182bd7b8a7046c05381eb5ae64d2b190ea0743ff4dd83b9ddde1114"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
